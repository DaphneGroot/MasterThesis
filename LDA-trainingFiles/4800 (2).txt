Entropie.
Entropie ("S") is een belangrijk begrip in de thermodynamica. Het is op het fundamenteelste niveau een maat voor de "wanorde" of de "ontaarding" in een systeem, of liever de "waarschijnlijkheid", als het aantal mogelijke moleculaire configuraties van een macroscopische toestand (in termen van macroscopische grootheden druk, temperatuur, etc.) gedeeld door het totale aantal mogelijke moleculaire configuraties. Een toestand waarin macroscopische grootheden als druk en temperatuur ongelijk verdeeld zijn over een volume heeft in het algemeen veel minder realisatiemogelijkheden dan één met een gelijkmatige verdeling. De ongelijke verdeling van macroscopische grootheden in een geïsoleerd systeem (dat wil zeggen met een vast volume, zonder dat er energie in of uit kan) neigt dus op statistische gronden tot afvlakken van die ongelijkmatigheden. Een formele manier om dit uit te drukken is de tweede wet van de thermodynamica. Het begrip "entropie" werd geïntroduceerd door Rudolf Clausius.
Klassieke definitie.
Het bijzondere aan de entropie "S" is dat deze, in tegenstelling tot qrev, wel een toestandsfunctie is. De integraal van dS hangt dus alleen van de begin- en eindtoestand af en de integraal van een kringproces is dus altijd gelijk aan nul. De toestandsfunctie "S" is door de integraal op een constante na bepaald. Door de waarde van de entropie bij "T" = 0 Kelvin op nul te stellen zou eventueel ook een absolute entropie kunnen worden gedefinieerd, zie onder.
Bij een isentropisch proces is de entropie constant. Zo'n proces moet dus niet alleen verlopen zonder dat er warmte-energie in of uit kan, maar het moet ook omkeerbaar verlopen.
Als warme en koude materie met elkaar in contact gebracht worden binnen een geïsoleerd systeem, stroomt warmte spontaan van de warme naar de koude materie (dit is een voorbeeld van een irreversibel proces) en de entropie van de warme materie neemt minder af dan die van de koude materie toeneemt, zodat de totale entropie van het geïsoleerde systeem toeneemt, net zo lang tot de temperatuur overal in het systeem hetzelfde is; het geïsoleerde systeem is dan in evenwicht en de entropie heeft het bijbehorende maximum voor dat geïsoleerde systeem bereikt.
Toepassing op een ideaal gas.
waarin formula_5 de warmtecapaciteit bij constante druk is en formula_6 de warmtecapaciteit bij constant volume, en
waarin formula_8 (5/3 voor een eenatomig gas en 7/5 voor een twee-atomig gas), "n" het aantal mol en "R" de gasconstante.
Voor een isentropisch proces is uit (ii) dan gemakkelijk af te leiden dat
Geschiedenis.
Hoewel aanvankelijk allerminst duidelijk was wat de nieuw geformuleerde functie precies voorstelde, bleek het wel mogelijk een tweetal fenomenen ermee te verklaren die tot dan moeilijk te begrijpen waren.
Eerst met de komst van de atoomtheorie en de statistische mechanica, rond 1900, werd het mogelijk het begrip entropie een statistische onderbouwing te geven, waarbij Maxwell, Gibbs en Boltzmann de hoofdrol speelden.
Analogie.
gelijk aan 0 omdat W=1. Oftewel deze toestand heeft de laagste entropie. (Entropie kan immers niet negatief zijn omdat noch q noch T negatief zijn). Wanneer er geen scheidingsplaat aanwezig is, dan zullen bij het schudden van de doos de knikkers telkens weer een andere rangschikking maken. Het schudden in dit voorbeeld is een metafoor voor de toevoer van warmte. Van belang is dat door het schudden en het weghalen van het scheidingsvlak de rode (en ook de witte) meer ruimte hebben gekregen. Daardoor zijn er meer verschillende ordeningen van de witte en rode ballen in de doos mogelijk.
Iedere knikker heeft nu twee realisaties: hij kan in de linker- of in de rechterhelft zitten. Als er evenveel witte als rode initieel in de doos waren, zeg N in totaal, dan zijn er in totaal W=2N realisaties. De entropie na het schudden is dan
Deze waarde is groter dan de beginsituatie en dus zal het systeem van knikkers spontaan evolueren naar een toestand van gelijkmatige menging. Dit komt overeen met de klassieke waarneming dat in een geïsoleerd systeem de entropie de spontane neiging heeft zo groot mogelijk te worden.
Het model van knikkers in een doos is van een eenvoudig soort. Knikkers trekken elkaar niet (meetbaar) aan, alle ordeningen hebben een gelijke energie, en dus heeft een bepaalde ordening van rood en wit een gelijke kans om voor te komen. De weegfactor van alle realisaties is dan gelijk aan 1. Verder, als er in het geheel niet geschud wordt, dan is als het ware de absolute temperatuur gelijk aan nul. En dan is volgens de derde wet van de thermodynamica de absolute entropie gelijk aan nul wanneer de rode apart van de witte liggen en beide kleuren netjes gerangschikt zijn.
Het label 'wanorde' kan ons een idee geven van wat we ons bij entropie moeten voorstellen en het voorbeeld met de knikkers kan een nuttig hulpmiddel zijn om een en ander aanschouwelijk te maken. In werkelijkheid is entropie niet hetzelfde als wanorde omdat het aantal realisaties W ook in sterke mate afhangt van welke energietoestanden ieder molecuul heeft en niet alleen van de plaats waar het zich bevindt.
Absolute entropie.
Het is over het algemeen in de reële wereld vrij moeilijk om de "absolute entropie" van een systeem te bepalen. Daartoe zou het systeem eerst naar het absolute nulpunt moeten worden afgekoeld, zodat de moleculen niet meer bewegen, en bovendien moeten de moleculen in de meest stabiele toestand zijn. In dat specifieke geval is de absolute entropie gelijk aan nul (derde wet van de thermodynamica). De verandering van deze stabiele toestand bij 0 K naar het uitgangspunt geeft de absolute entropie.
Gelukkig is het voor de praktische toepassing van de entropie meestal voldoende om met entropie-verschillen te rekenen. En dat is experimenteel vrij goed mogelijk. Entropieveranderingen als gevolg van "omkeerbare" temperatuurverandering berekent men met behulp van de warmtecapaciteit: de integraal van het quotiënt van warmtecapaciteit en temperatuur over het temperatuurveranderingsgebied.
Standaardentropie.
In thermodynamische tabellen wordt vaak de "standaardentropie" van een stof of een proces weergegeven. Deze waarde wordt weergegeven met een plimsoll superscript o en geldt voor het proces onder standaardomstandigheden
Relatie met de informatietheorie.
Maxwells demon (groen) kan de entropie niet verlagen door snelle moleculen (rood) wel van A naar B en niet van B naar A door te laten en trage moleculen (blauw) wel van B naar A en niet van A naar B door te laten.
Entropie in de thermodynamica is equivalent met de entropie zoals die in de informatietheorie wordt gebruikt, de zogenaamde Shannon entropie, wanneer je voor de kansen formula_13 de kansverdeling over alle mogelijke quantumtoestanden van het systeem neemt. Deze equivalentie is algemeen geldig en kan zelfs worden gebruikt voor systemen die niet in thermodynamisch evenwicht zijn. Wanneer de entropie wordt uitgedrukt in bits, dan komt dit overeen met de hoeveelheid informatie die nodig is om de precieze microtoestand van het systeem te specificeren.
Deze equivalentie maakt het inzichtelijk waarom zelfs Maxwells demon de Tweede Hoofdwet niet kan overtreden. Om bijvoorbeeld een temperatuurverschil te creëren in een gas door iedere keer een luikje open te doen wanneer er een snelle molecule aankomt, lijkt het alsof je de entropie van een gas kunt verlagen. Nu is het inderdaad zo dat de entropie van het gas verlaagd kan worden, maar de demon moet wel iedere keer een beslissing nemen op grond van de snelheid van de molecule die langs komt. De informatie over de vorige molecule zit dan nog in zijn geheugen, dus op een gegeven moment raakt zijn geheugen vol. Bovendien zou de demon zelf snel in temperatuur oplopen.
De daling van de entropie van het gas uitgedrukt in bits die een ideale demon kan bereiken is precies gelijk aan de geheugencapaciteit van de demon. Er is dan dus minder informatie nodig om de microtoestand van het gas te specificeren maar precies zoveel meer informatie is er nodig om de toestand van het geheugen van de demon te specificeren. Wissen van het geheugen is geen optie, want daardoor neemt de entropie van de omgeving toe met ten minste hetzelfde bedrag.
