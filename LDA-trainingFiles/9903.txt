Gedistribueerd programmeren.
Gedistribueerd programmeren (ook wel parallel programmeren) is een techniek van programmeren en programma-ontwerp, waarbij een computerprogramma bestaat uit meerdere deelprogramma's die al dan niet gelijktijdig uitgevoerd kunnen worden. Multiprocessor-machines zijn in staat om betere prestaties te behalen door dit soort programmering.
Werking.
Bij gedistribueerd programmeren wordt een enkele taak opgesplitst in meerdere "subtaken" die relatief onafhankelijk berekend en achteraf weer samengevoegd kunnen worden tot een enkel resultaat. Dit kan binnen een enkele computer zijn, of verspreid over meerdere systemen. In het tweede geval is de term "distributed computing" van toepassing. Gedistribueerd programmeren is het meest effectief bij taken die gemakkelijk in stukken opgedeeld kunnen worden zoals (sommige) puur wiskundige problemen.
"Distributed computing" (gedistribueerd rekenen) kan gedefinieerd worden als een methode waar gewerkt wordt door verschillende computers, gelinkt middels een communicatienetwerk.
Pioniers in het gebied van gedistribueerd programmeren zijn onder anderen Edsger Dijkstra en Tony Hoare.
Vergelijking met sequentieel programmeren.
Een vaak voorkomende beschrijving van de werking van een computer is die waarin een programma een recept is: een lijst van instructies die één voor één, van begin tot eind door de computer uitgevoerd worden (zie ook Von Neumann-cyclus). Dit model van programma's uitvoeren door een computer staat bekend als sequentiële uitvoering van een programma.
Een "gedistribueerd systeem" is een computerprogramma dat bestaat uit een aantal sequentiële programma's die gelijktijdig kunnen worden uitgevoerd. Dat wil zeggen, ieder deelprogramma wordt op dezelfde manier uitgevoerd als een sequentieel programma, maar ten opzichte van elkaar kunnen de instructies van de subprogramma's gelijktijdig uitgevoerd worden.
Gedistribueerd programmeren kent vele varianten van precieze uitvoering; de deelprogramma's kunnen op verschillende processoren uitgevoerd worden of afwisselend op één processor. Er kan gebruikgemaakt worden van meerdere computers in een netwerk of een enkele computer met vele processoren. Iedere variant kent zijn voor- en nadelen.
Interleaving.
De techniek van het gedistribueerd programmeren geeft een software-ontwikkelaar extra flexibiliteit in zijn ontwerp, omdat hij de mogelijkheid heeft om een groot programma te verdelen over losse blokken die samenwerken en mogelijk zelfs van de rekenkracht van meerdere processoren tegelijkertijd gebruikmaken. Deze extra flexibiliteit heeft echter wel zijn prijs in termen van extra complexiteit in het ontwerp van de deelprogramma's van een gedistribueerd programma.
en de verlaging op een soortgelijke manier, waarmee de precieze volgorde van onderlinge statements en hun effecten op het geheugen een nog veel groter aantal variaties kent.
Dit fenomeen (dat de verschillende statements in een programma in verschillende volgorden kunnen worden uitgevoerd) heet "interleaving". En een bepaalde volgorde uit alle mogelijkheden wordt ook een "(specifieke) interleaving" genoemd.
Atomiciteit.
Zoals eerder opgemerkt is het bij het gedistribueerd programmeren altijd de vraag hoe statements nu precies uitgevoerd worden en welke statements onderbroken kunnen worden en zo onverwachte uitwerkingen kunnen hebben. Het is daarom bij het gedistribueerd programmeren altijd zaak te weten welke statements ondeelbaar zijn (dat wil zeggen niet onderbroken kunnen worden en dus altijd de verwachte uitwerking hebben). Een dergelijk, ondeelbaar statement wordt een "atomair" statement genoemd.
Een bijzonder soort van atomair statement is het "one-point statement": dit is een statement waarin maximaal één gedeelde variable maximaal één keer voorkomt (dus ook: wordt uitgelezen, of aan wordt toegekend, maar niet beide). Een dergelijk statement is altijd atomair, omdat in een dergelijk statement gebruik wordt gemaakt van het feit dat een computer niet tegelijkertijd kan lezen van en schrijven naar één positie in het geheugen van de computer. Als er dan ook niet van meer dan één gedeelde positie in het geheugen gebruik wordt gemaakt, is het statement per definitie atomair. Bij het algoritme-ontwerp op academisch niveau wordt dan ook vaak gestreefd naar algoritmes op basis van one-point statements - de werking daarvan hangt namelijk niet af van bijzondere maatregelen in een programmeertaal om te voorkomen dat dingen verkeerd gaan.
Synchronisatie.
Toch lost het one-point statement niet alle problemen op. Het is soms nodig dat deelprogramma's in een gedistribueerd programma op hoger niveau met elkaar rekening houden dan alleen op het niveau van toegang tot een positie in het geheugen. Te denken valt aan toegang tot randapparatuur, of ervoor zorgen dat een deelprogramma niet te ver op alle andere voor gaat lopen. Het is dan nodig de uitvoering van deelprogramma's te synchroniseren.
Synchronisatie komt er altijd op neer dat een deelprogramma tijdelijk stilgezet wordt totdat aan een bepaalde voorwaarde voldaan is. Hiervoor bestaan vele synchronisatie-mechanismen; voorbeelden hiervan zijn seinpalen (in de literatuur vaak "semaforen" genoemd), monitors, blokkerende kanalen of busy waiting.
Dit stilzetten is echter ook niet probleemloos: bij onnauwkeurig ontwerp van een gedistribueerd programma dreigt het gevaar van deadlock (alle deelprogramma's komen stil te staan en blijven eeuwig op elkaar wachten), livelock (deelprogramma's blijven, in reactie op andere deelprogramma's, steeds nutteloze handelingen herhalen) of individual starvation (het systeem als geheel loopt door, maar een of meerdere deelprogramma's worden zo snel uitgevoerd dat de rest niet meer aan bod komt). Dat laatste gevaar dreigt ook als in een gedistribueerde programma's met "prioriteiten" wordt gewerkt (waarbij een deelprogramma meer recht heeft op processortijd dan andere deelprogramma's).
"Zie ook wederzijds uitsluitingsalgoritme van Peterson"
De voor- en nadelen van gedistribueerde programma's.
Over het algemeen is het ontwerp van een gedistribueerd programma aanzienlijk ingewikkelder dan dat van een sequentieel programma. Daarbij geldt ook nog dat een gedistribueerd programma niet méér problemen op kan lossen dan een sequentieel programma (zie ook de Turingmachine). Toch geniet het gedistribueerd programmeren veel en aanhoudend ook meer en meer aandacht.
Een reden daarvoor is voornamelijk dat een gedistribueerd programma weliswaar niet krachtiger kan zijn dan een sequentieel programma, maar wel sneller. Gedistribueerde programma's worden dan ook vaak ingezet om de rekenkracht van vele computers te bundelen in de oplossing van één probleem (zie ook "distributed computing", SETI, "grid computing").
Varianten en technieken van gedistribueerd programmeren.
Over de jaren zijn er veel varianten en technieken van gedistribueerd programmeren ontwikkeld. Zowel op het gebied van hardware-architecture als van software-implementaties zijn zeer vele varianten op het thema ontstaan.
Variaties in de hardware.
Als het gaat over gedistribueerd programmeren en het uitvoeren van gedistribueerde programma's, gaat het over het algemeen om twee dingen: processoren (die instructies uitvoeren) en geheugen (waarin data opgeslagen worden).
Processoren.
Bij het uitvoeren van gedistribueerde programma's is het mogelijk gebruik te maken van één enkele processor, dan wel van meerdere. In het geval van meerdere is ieder aantal mogelijk tussen 2 en het aantal deelprogramma's dat uitgevoerd moet worden (meer processoren dan dat kan ook, maar is niet nuttig) -- in dit geval spreekt men vaak van "parallel programmeren", omdat deelprogramma's dan zeker parallel aan elkaar uitgevoerd worden. In het geval er meer deelprogramma's zijn dan processoren, is het nodig dat een onderliggend systeem (zie besturingssysteem) ervoor zorgt dat ieder deelprogramma regelmatig toegang verkrijgt tot een processor (zie task switching, load balancing, besturingssysteem).
In het geval van meerdere processoren zijn er ook weer variaties mogelijk -- te denken valt aan meerdere processoren verbonden met een bus, maar ook processoren verbonden via een netwerk zijn mogelijk. In dit laatste geval is het mogelijk dat er een speciaal ingericht netwerk met een specifieke vorm wordt gebruikt, of een generiek netwerk. In het eerste geval kan met de vorm van het netwerk rekening worden gehouden bij het ontwerp van het parallelle programma om zo optimale rekensnelheden te bereiken; bekende vormen van netwerken zijn het lineaire netwerk (processoren in een rij geschakeld), het cykel-netwerk (een uitbreiding van het lineaire netwerk waarbij er een cirkel gevormd wordt) en de taurus (een vierkant van processoren, waarbij iedere processor verbonden is met buren links, rechts boven en onder). In het tweede geval gaat het vaak over netwerken waarvan de samenstelling niet specifiek voor één taak bedoeld is, zoals een LAN, WAN of het internet (zie Distributed computing en grid computing).
Geheugens.
Ook in het gebruik van geheugen is variatie mogelijk. Met name gaat het over de vraag of alle deelprogramma's in het gedistribueerde programma geheugen delen of dat ieder deelprogramma (of processor) een eigen geheugen heeft. Dit heeft voornamelijk weerslag op het gebruik van synchronisatie-mechanismen: seinpalen zijn bijvoorbeeld handiger bij gedeeld geheugen, blokkerende kanalen zijn makkelijker bij individueel geheugen.
Uiteraard zijn variaties in processoren en geheugens ook te combineren: vier processoren voor één geheugen bijvoorbeeld en meerdere van dergelijke blokken. Zie ook SIMD, MIMD.
Variaties in de software.
Ook in de software-uitvoering van het gedistribueerde programma is veel variatie ontstaan, zowel op het hogere niveau van programma-architectuur als op het lagere niveau van het organiseren van deelprogramma's.
Processen en threads.
Ook op lager niveau is variatie ontstaan in de precieze implementatie van gedistribueerde programma's. Bekende termen hier zijn processen en threads (zie ook multitasking).
Het gebruik van processen staat bekend als "multiprocessing" (waarin ieder deelprogramma door het besturingssysteem als een volwaardig programma wordt gezien met eigen blok geheugen en andere middelen). Bij het gebruik van multiprocessing is het mogelijk ieder deelprogramma te voorzien van alle flexibiliteit die een volwaardig programma ook heeft. Dit is echter wel een zware belasting voor een systeem.
Het gebruik van threads heet "multithreading". Een thread is een soort van "deelproces" dat draait op de middelen en een stuk van het geheugen van een normaal proces -- waarbij het mogelijk is meerdere threads aan één proces te verbinden. Dit levert een aanzienlijk lagere belasting van het systeem op, maar een thread is wel minder flexibel qua toegang tot het systeem dan een volwaardig proces. Het komt echter vaak genoeg voor dat een parallel programma geen zware systeemtoegang nodig heeft en dus probleemloos met threads uit de voeten kan in plaats van processen.
